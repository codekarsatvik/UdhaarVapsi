<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Debt Collection Voice Agent - Test Interface</title>
    <style>
        body {
            font-family: 'Inter', sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin-bottom: 20px;
        }
        .test-section {
            margin-bottom: 30px;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 8px;
        }
        .test-section h2 {
            margin-top: 0;
            color: #2563eb;
        }
        .controls {
            margin: 20px 0;
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
        }
        button {
            padding: 10px 20px;
            border: none;
            border-radius: 4px;
            background-color: #2563eb;
            color: white;
            cursor: pointer;
            transition: background-color 0.2s;
        }
        button:hover {
            background-color: #1d4ed8;
        }
        button:disabled {
            background-color: #ccc;
        }
        input, textarea {
            width: 100%;
            padding: 8px;
            margin: 5px 0;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        .result {
            margin-top: 10px;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 4px;
            background-color: #f8f9fa;
            white-space: pre-wrap;
        }
        .audio-player {
            margin-top: 10px;
            width: 100%;
        }
        .status {
            margin: 10px 0;
            padding: 10px;
            border-radius: 4px;
        }
        .success {
            background-color: #d1fae5;
            color: #065f46;
        }
        .error {
            background-color: #fee2e2;
            color: #991b1b;
        }
        .log {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 4px;
            height: 200px;
            overflow-y: auto;
            margin-bottom: 20px;
            border: 1px solid #dee2e6;
        }
        .transcript {
            background: #e9ecef;
            padding: 15px;
            border-radius: 4px;
            margin-top: 10px;
            border: 1px solid #dee2e6;
        }
        .log-entry {
            margin: 5px 0;
            font-size: 14px;
            color: #495057;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>AI Debt Collection Voice Agent - Test Interface</h1>
        <div class="controls">
            <button onclick="startRecording()">Start Recording</button>
            <button onclick="stopRecording()">Stop Recording</button>
            <button onclick="playGreeting()">Play Greeting</button>
        </div>
        <div class="log" id="log"></div>
        <div class="transcript" id="transcript"></div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        const log = document.getElementById('log');
        const transcript = document.getElementById('transcript');

        function logMessage(message, type = 'info') {
            const entry = document.createElement('div');
            entry.className = `log-entry ${type}`;
            entry.textContent = `${new Date().toLocaleTimeString()}: ${message}`;
            log.appendChild(entry);
            log.scrollTop = log.scrollHeight;
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    
                    // Convert blob to base64
                    const reader = new FileReader();
                    reader.readAsDataURL(audioBlob);
                    reader.onloadend = async () => {
                        const base64Audio = reader.result.split(',')[1]; // Remove data URL prefix
                        
                        try {
                            logMessage('Sending audio for transcription...');
                            const response = await fetch('/api/test-stt', {
                                method: 'POST',
                                headers: {
                                    'Content-Type': 'application/json'
                                },
                                body: JSON.stringify({
                                    audio_data: base64Audio,
                                    file_name: 'recording.wav'
                                })
                            });
                            const data = await response.json();
                            
                            if (data.transcript) {
                                logMessage(`Transcription: ${data.transcript}`, 'success');
                                transcript.textContent = `Transcription: ${data.transcript}`;
                                
                                // Get LLM response
                                logMessage('Getting AI response...');
                                const llmResponse = await fetch('/api/test-llm', {
                                    method: 'POST',
                                    headers: { 'Content-Type': 'application/json' },
                                    body: JSON.stringify({ transcript: data.transcript })
                                });
                                const llmData = await llmResponse.json();
                                
                                if (llmData.response) {
                                    logMessage(`AI Response: ${llmData.response}`, 'success');
                                    
                                    // Get TTS response
                                    logMessage('Converting response to speech...');
                                    const ttsResponse = await fetch('/api/test-tts', {
                                        method: 'POST',
                                        headers: { 'Content-Type': 'application/json' },
                                        body: JSON.stringify({ text: llmData.response })
                                    });
                                    
                                    if (ttsResponse.ok) {
                                        const audioBlob = await ttsResponse.blob();
                                        const audioUrl = URL.createObjectURL(audioBlob);
                                        const audio = new Audio(audioUrl);
                                        audio.play();
                                        logMessage('Playing AI response...', 'success');
                                    }
                                }
                            }
                        } catch (error) {
                            logMessage(`Error: ${error.message}`, 'error');
                        }
                    };
                };

                mediaRecorder.start();
                logMessage('Recording started...', 'success');
            } catch (error) {
                logMessage(`Error: ${error.message}`, 'error');
            }
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                logMessage('Recording stopped...', 'success');
            }
        }

        async function playGreeting() {
            try {
                logMessage('Playing greeting...');
                const response = await fetch('/api/test-tts', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ 
                        text: "Hello, I am your AI debt collection agent. How can I help you today?"
                    })
                });
                
                if (response.ok) {
                    const audioBlob = await response.blob();
                    const audioUrl = URL.createObjectURL(audioBlob);
                    const audio = new Audio(audioUrl);
                    audio.play();
                    logMessage('Playing greeting...', 'success');
                }
            } catch (error) {
                logMessage(`Error: ${error.message}`, 'error');
            }
        }
    </script>
</body>
</html> 